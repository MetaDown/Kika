{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7.11 64-bit ('py_tf': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"name":"UNET-api.ipynb","provenance":[]},"interpreter":{"hash":"ec549830669b736237f7d5bc49e5807896bc58d84b6f7c122708164714f93445"}},"cells":[{"cell_type":"code","execution_count":1,"source":["from tensorflow.keras.layers import Conv2D, BatchNormalization, Conv2DTranspose, MaxPooling2D, UpSampling2D, concatenate, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping, History, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import load_img\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import cv2\n","import os"],"outputs":[],"metadata":{"id":"kLDzqhfUZd4Z"}},{"cell_type":"code","execution_count":2,"source":["gpus = tf.config.list_physical_devices('GPU')\n","print(\"Los dispositivos encontrados son: \", gpus)\n","if gpus:\n","  try:\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"GPUs físicos,\", len(logical_gpus), \"GPUs lógicos\")\n","  except RuntimeError as e:\n","    print(e)\n","print(\"----------------------------------------------------- \\n\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Los dispositivos encontrados son:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","1 GPUs físicos, 1 GPUs lógicos\n","----------------------------------------------------- \n","\n"]}],"metadata":{"id":"XVYzmFgeZd4c","outputId":"930cefa5-7096-42ff-f884-b70eba3f9a6e"}},{"cell_type":"code","execution_count":3,"source":["#Dirección de directorios de entrenamient y validación\n","input_dir= \"/home/revientaelp/Documentos/Bases de datos/Kika/300/ent/org\"\n","target_dir= \"/home/revientaelp/Documentos/Bases de datos/Kika/300/ent/msk\"\n","\n","val_input_it= \"/home/revientaelp/Documentos/Bases de datos/Kika/300/val/org\"\n","val_target_it= \"/home/revientaelp/Documentos/Bases de datos/Kika/300/val/msk\"\n","\n","#Listas de las imagenes\n","img_size = (304, 304)\n","num_classes = 2\n","batch_size_t = 1\n","batch_size_v = 1\n","\n","input_img_paths = sorted(\n","    [\n","        os.path.join(input_dir, fname)\n","        for fname in os.listdir(input_dir) \n","        if fname.endswith(\".png\")\n","    ]\n",")\n","\n","target_img_paths = sorted(\n","    [\n","        os.path.join(target_dir, fname)\n","        for fname in os.listdir(target_dir)\n","        if fname.endswith(\".png\") and not fname.startswith(\".\")\n","    ]\n",")\n","\n","val_input_paths = sorted(\n","    [\n","        os.path.join(val_input_it, fname)\n","        for fname in os.listdir(val_input_it)\n","        if fname.endswith(\".png\") and not fname.startswith(\".\")\n","    ]\n",")\n","\n","val_target_paths = sorted(\n","    [\n","        os.path.join(val_target_it, fname)\n","        for fname in os.listdir(val_target_it)\n","        if fname.endswith(\".png\") and not fname.startswith(\".\")\n","    ]\n",")\n","\n","ID_input_t= np.arange(len(input_img_paths))\n","ID_input_v= np.arange(len(val_input_paths))"],"outputs":[],"metadata":{"id":"sRvjjlCaZd4d"}},{"cell_type":"code","execution_count":4,"source":["#Generador de los ejemplos de entrada\n","class MiClasificacion(tf.keras.utils.Sequence):\n","    def __init__(self, input_img_paths, target_img_paths, ID_input, shuffle= True, batch_size= 32, img_size= (304, 304, 3), train= True):\n","\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        self.input_img_paths = input_img_paths\n","        self.target_img_paths = target_img_paths\n","        self.ID_input = ID_input\n","        self.shuffle= shuffle\n","        self.cont= 0\n","        self.train= train\n","\n","    def __len__(self):\n","        # Calcula el numero de pasos por epoca.\n","        return len(self.target_img_paths) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n","\n","        # Combinamos los datos en cada epoca, pero solo para los datos de entrenamiento\n","        if (self.cont== len(self.target_img_paths) // self.batch_size) or (self.cont== 0) and (self.train== True):\n","            np.random.shuffle(self.ID_input)\n","            self.cont= 0\n","            \n","        i = idx * self.batch_size\n","        batch_img= []\n","        batch_tar= []\n","        if self.train== True:\n","            self.cont =self.cont +1\n","\n","        #De acuerdo a los indices en ID_input tomamos las imagenes de los paths correspondientes\n","        for ig in self.ID_input[i : i + self.batch_size]:\n","            batch_img.append(self.input_img_paths[ig])\n","            batch_tar.append(self.target_img_paths[ig])\n","\n","        X, Y= self.__data_generation(batch_img, batch_tar)                                          # Mandamos llamar a la funcion generadora de los ejemplos\n","\n","        return X, Y\n","\n","    def __data_generation(self, biip, btip):\n","            \n","        # Creacion del tensor con dimensiones las dimensiones de entrada\n","        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n","        #x = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"float32\")                    # Generamos un tensor que almacenara las imagenes importadas     \n","        for j, path in enumerate(biip):\n","            img = load_img(path, target_size=self.img_size)                                         # Cragamos las imagenes de entrada \n","            x[j] = np.array(img)/255.0                                                              # Normalizamos y agregamos la imagen al tensor\n","\n","        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")                      # Generamos un tensor que almacenara las mascaras importadas \n","        for j, path in enumerate(btip):\n","            img = load_img(path,target_size= self.img_size,color_mode=\"grayscale\")                  # Importamos la imagne en escala de grises\n","            y[j] = np.expand_dims(img, 2)\n","            for r in range(y.shape[1]):\n","                for g in range(y.shape[2]):\n","                    if y[j, r, g, 0]!= 0:                                                           # Nos aseguramos de que las venas etiquetadas resulten se un 1\n","                        y[j, r, g, 0]= 1\n","\n","        return x, y"],"outputs":[],"metadata":{"id":"ZaGKznb6Zd4e"}},{"cell_type":"code","execution_count":5,"source":["# Generamos la secuencia del DownSampling de UNET\n","def conv_code(entrada, filtros, ker_reg= None):\n","  x= Conv2D(filtros, 3, padding= \"same\", activation= \"relu\",  kernel_regularizer= ker_reg)(entrada)\n","  x= BatchNormalization()(x)\n","\n","  x= Conv2D(filtros, 3, padding= \"same\", activation= \"relu\", kernel_regularizer= ker_reg)(x)\n","  x= BatchNormalization()(x)\n","\n","  residual= x\n","  x= MaxPooling2D(3, strides= 2, padding= \"same\")(x)\n","  \n","  return residual, x\n","\n","# Generamos la secuencia BottleNeck correspondiente a l\n","def botle(entrada):\n","  x= Conv2D(512, 3, padding= \"same\", activation= \"relu\",  kernel_regularizer= tf.keras.regularizers.L1L2(l1=0.001, l2=0.001))(entrada)\n","  x= BatchNormalization()(x)\n","  x= Conv2D(512, 3, padding= \"same\", activation= \"relu\",  kernel_regularizer= tf.keras.regularizers.L1L2(l1=0.001, l2=0.001))(x)\n","  x= BatchNormalization()(x)\n","\n","  x= Conv2DTranspose(256, 3,padding= \"same\" )(x)\n","\n","  return x\n","\n","# Generamos el UPSAMPLING \n","def conv_decode(entrada, filtros, ker_reg= None):\n","  x= Conv2D(filtros, 3, padding= \"same\", activation= \"relu\", kernel_regularizer= ker_reg)(entrada)\n","  x= BatchNormalization()(x)\n","  x= Conv2D(filtros, 3, padding= \"same\", activation= \"relu\", kernel_regularizer= ker_reg)(x)\n","  x= BatchNormalization()(x)\n","\n","  x= Conv2DTranspose(int(filtros/2), 3,padding= \"same\" )(x)\n","\n","  return x\n","\n","# Para ir subiendo entre capa y capa\n","def crop_and_cat(entrada, res):\n","  x= UpSampling2D(2)(entrada)\n","  \n","  return concatenate([x, res])\n","\n","#La capa final de salida\n","def capa_final(entrada, filtros, num_clases):\n","  x= Conv2D(filtros, 3, padding= \"same\", activation= \"relu\")(entrada)\n","  x= BatchNormalization()(x)\n","\n","  x= Conv2D(filtros, 3, padding= \"same\", activation= \"relu\")(x)\n","  x= BatchNormalization()(x)\n","\n","  x= Conv2D(num_clases, 3, padding= \"same\", activation= \"softmax\")(x)\n","\n","  return x"],"outputs":[],"metadata":{"id":"r7kPeHaoZd4f"}},{"cell_type":"code","execution_count":9,"source":["#Generamos el modelo\n","def get_model(img_size, num_classes):\n","  inputs= tf.keras.Input(shape= img_size+ (3,))\n","  \n","  res_1, conv_1= conv_code(inputs, 64)\n","  res_2, conv_2= conv_code(conv_1, 128)\n","  res_3, conv_3= conv_code(conv_2, 256, tf.keras.regularizers.L1L2(l1=0.001, l2=0.001))\n","\n","  bot= botle(conv_3)\n","\n","  crop1= crop_and_cat(bot, res_3)\n","  decode_3= conv_decode(crop1, 256, tf.keras.regularizers.L1L2(l1=0.001, l2=0.001))\n","\n","  crop2= crop_and_cat(decode_3, res_2)\n","  decode_2= conv_decode(crop2, 128)\n","\n","  crop3= crop_and_cat(decode_2, res_1)\n","  x= Dropout(rate= 0.5)(crop3)\n","  outputs= capa_final(x, 64, 2)\n","\n","  model= tf.keras.Model(inputs, outputs)\n","  return model\n","\n","def entrenamient_modelo(train_gen, val_gen, DIR_save, epocas= 30, visualizacion= False):\n","\n","    #Generamos los callback necesarios\n","    checkpoint= ModelCheckpoint(DIR_save+ \"03092021_S1.hdf5\", monitor= 'val_loss', save_best_only= True, mode= 'min', save_weights_only= False)\n","    reduceLROnPlat= ReduceLROnPlateau(monitor= 'val_loss', factor= 0.8, patience= 3, min_delta= 0.001, cooldown= 7, min_lr= 0.0001)\n","    #tensorboard_callback = TensorBoard(log_dir= datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","    callbacks= [EarlyStopping(patience= 12,  monitor='val_loss'), History(), checkpoint, reduceLROnPlat]#, tensorboard_callback]\n","    metrica= [tf.keras.metrics.CategoricalAccuracy()]\n","\n","    #Compilamos con la funcion perdida y el optimizador que utilizaremos\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.001), loss= \"sparse_categorical_crossentropy\", metrics= metrica) #loss= \"binary_crossentropy\", metrics= ['accuracy'])\n","    history= model.fit(train_gen, epochs=epocas, validation_data=val_gen, callbacks=callbacks)\n","  \n","def infor_model(img_size):\n","  model = get_model(img_size, 2)                                   # Generamos el modelo con el tamaño de las imagenes de entrada y la salida esperada\n","  model.summary()  \n","\n","def carga_mod(DIR):\n","    return tf.keras.models.load_model(DIR)"],"outputs":[],"metadata":{"id":"tU2CwEL1Zd4f"}},{"cell_type":"code","execution_count":10,"source":["#Creamos los generadoras para el entrenamiento y la validación\n","train_gen = MiClasificacion(\n","    input_img_paths, target_img_paths, ID_input_t, shuffle= True, batch_size= batch_size_t, img_size= img_size, train= True\n",")\n","\n","val_gen = MiClasificacion(\n","    val_input_paths, val_target_paths, ID_input_v, shuffle= True, batch_size=batch_size_v, img_size= img_size, train= False\n",")\n","\n","#infor_model((304, 304))"],"outputs":[],"metadata":{"id":"8CSJHp7jZd4g"}},{"cell_type":"code","execution_count":11,"source":["# Comenzamos el entrenamiento\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Grises/SGD/140521/14052021_400.hdf5'\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Filtros/SGD/120521/12052021_400.hdf5'\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Normales/SGD/140521/14052021_400.hdf5'\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Comb/SGD/150521/15052021_400.hdf5'\n","\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Filtros/ADAM/240421/24042021_400_2.hdf5'\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Normales/ADAM/040521_1/04052021_400.hdf5'\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Comb/ADAM/080521/08052021_400.hdf5'\n","#DIR= 'E:/rortiz324/Proyecto/Bases_de_datos/ModelosGuardados/Grises/ADAM/300421/29042021_400_1.hdf5'\n","\n","#model= carga_mod(DIR)\n","model= get_model(img_size, 2)\n","\n","DIR_save_best= '/home/revientaelp/Documentos/Modelos/'\n","entrenamient_modelo(train_gen, val_gen, DIR_save_best, 400, False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","17833/17833 [==============================] - 2118s 119ms/step - loss: 2.2359 - categorical_accuracy: 0.8959 - val_loss: 2.4010 - val_categorical_accuracy: 0.8324 - lr: 0.0010\n","Epoch 2/400\n","17833/17833 [==============================] - 2108s 118ms/step - loss: 1.7561 - categorical_accuracy: 0.8871 - val_loss: 1.5997 - val_categorical_accuracy: 0.8008 - lr: 0.0010\n","Epoch 3/400\n","17833/17833 [==============================] - 2054s 115ms/step - loss: 1.6418 - categorical_accuracy: 0.8841 - val_loss: 1.8765 - val_categorical_accuracy: 0.7660 - lr: 0.0010\n","Epoch 4/400\n","17833/17833 [==============================] - 2056s 115ms/step - loss: 1.2727 - categorical_accuracy: 0.8819 - val_loss: 1.1335 - val_categorical_accuracy: 0.8637 - lr: 0.0010\n","Epoch 5/400\n","17833/17833 [==============================] - 2054s 115ms/step - loss: 0.9363 - categorical_accuracy: 0.8804 - val_loss: 1.1700 - val_categorical_accuracy: 0.8289 - lr: 0.0010\n","Epoch 6/400\n","17833/17833 [==============================] - 2054s 115ms/step - loss: 0.9161 - categorical_accuracy: 0.8792 - val_loss: 1.2261 - val_categorical_accuracy: 0.7810 - lr: 0.0010\n","Epoch 7/400\n","17833/17833 [==============================] - 2049s 115ms/step - loss: 0.9010 - categorical_accuracy: 0.8784 - val_loss: 1.1393 - val_categorical_accuracy: 0.8038 - lr: 0.0010\n","Epoch 8/400\n","17833/17833 [==============================] - 2051s 115ms/step - loss: 0.7140 - categorical_accuracy: 0.8774 - val_loss: 1.1310 - val_categorical_accuracy: 0.7827 - lr: 8.0000e-04\n","Epoch 9/400\n","17833/17833 [==============================] - 2053s 115ms/step - loss: 0.7188 - categorical_accuracy: 0.8769 - val_loss: 1.2131 - val_categorical_accuracy: 0.7395 - lr: 8.0000e-04\n","Epoch 10/400\n","17833/17833 [==============================] - 2054s 115ms/step - loss: 0.7190 - categorical_accuracy: 0.8765 - val_loss: 1.5325 - val_categorical_accuracy: 0.7120 - lr: 8.0000e-04\n","Epoch 11/400\n","17833/17833 [==============================] - 2055s 115ms/step - loss: 0.7194 - categorical_accuracy: 0.8762 - val_loss: 1.0237 - val_categorical_accuracy: 0.8086 - lr: 8.0000e-04\n","Epoch 12/400\n","17833/17833 [==============================] - 2056s 115ms/step - loss: 0.7144 - categorical_accuracy: 0.8759 - val_loss: 1.0647 - val_categorical_accuracy: 0.8109 - lr: 8.0000e-04\n","Epoch 13/400\n","17833/17833 [==============================] - 2059s 115ms/step - loss: 0.7146 - categorical_accuracy: 0.8756 - val_loss: 0.9870 - val_categorical_accuracy: 0.8232 - lr: 8.0000e-04\n","Epoch 14/400\n","17833/17833 [==============================] - 2062s 116ms/step - loss: 0.7154 - categorical_accuracy: 0.8753 - val_loss: 0.9384 - val_categorical_accuracy: 0.8388 - lr: 8.0000e-04\n","Epoch 15/400\n","17833/17833 [==============================] - 2064s 116ms/step - loss: 0.7135 - categorical_accuracy: 0.8751 - val_loss: 0.9565 - val_categorical_accuracy: 0.8172 - lr: 8.0000e-04\n","Epoch 16/400\n","17833/17833 [==============================] - 2063s 116ms/step - loss: 0.7084 - categorical_accuracy: 0.8749 - val_loss: 0.9925 - val_categorical_accuracy: 0.8095 - lr: 8.0000e-04\n","Epoch 17/400\n","17833/17833 [==============================] - 2085s 117ms/step - loss: 0.7089 - categorical_accuracy: 0.8746 - val_loss: 1.1631 - val_categorical_accuracy: 0.7928 - lr: 8.0000e-04\n","Epoch 18/400\n","17833/17833 [==============================] - 2061s 116ms/step - loss: 0.6011 - categorical_accuracy: 0.8741 - val_loss: 1.0985 - val_categorical_accuracy: 0.7396 - lr: 6.4000e-04\n","Epoch 19/400\n","17833/17833 [==============================] - 2045s 115ms/step - loss: 0.6042 - categorical_accuracy: 0.8739 - val_loss: 0.9306 - val_categorical_accuracy: 0.8147 - lr: 6.4000e-04\n","Epoch 20/400\n","17833/17833 [==============================] - 2025s 114ms/step - loss: 0.6011 - categorical_accuracy: 0.8738 - val_loss: 1.0878 - val_categorical_accuracy: 0.7708 - lr: 6.4000e-04\n","Epoch 21/400\n","17833/17833 [==============================] - 2067s 116ms/step - loss: 0.6023 - categorical_accuracy: 0.8736 - val_loss: 0.9800 - val_categorical_accuracy: 0.8142 - lr: 6.4000e-04\n","Epoch 22/400\n","17833/17833 [==============================] - 2065s 116ms/step - loss: 0.5973 - categorical_accuracy: 0.8734 - val_loss: 1.0547 - val_categorical_accuracy: 0.7669 - lr: 6.4000e-04\n","Epoch 23/400\n","17833/17833 [==============================] - 2061s 116ms/step - loss: 0.5977 - categorical_accuracy: 0.8733 - val_loss: 0.9668 - val_categorical_accuracy: 0.8345 - lr: 6.4000e-04\n","Epoch 24/400\n","17833/17833 [==============================] - 2067s 116ms/step - loss: 0.5942 - categorical_accuracy: 0.8731 - val_loss: 0.8605 - val_categorical_accuracy: 0.8309 - lr: 6.4000e-04\n","Epoch 25/400\n","17833/17833 [==============================] - 2056s 115ms/step - loss: 0.5961 - categorical_accuracy: 0.8730 - val_loss: 1.1511 - val_categorical_accuracy: 0.7562 - lr: 6.4000e-04\n","Epoch 26/400\n","11493/17833 [==================>...........] - ETA: 10:54 - loss: 0.5937 - categorical_accuracy: 0.8724"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-7603b5e00c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mDIR_save_best\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'/home/revientaelp/Documentos/Modelos/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mentrenamient_modelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIR_save_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-f88be51fc63b>\u001b[0m in \u001b[0;36mentrenamient_modelo\u001b[0;34m(train_gen, val_gen, DIR_save, epocas, visualizacion)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#Compilamos con la funcion perdida y el optimizador que utilizaremos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmetrica\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loss= \"binary_crossentropy\", metrics= ['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"metadata":{"id":"vq6s4-j2Zd4h"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","\n","#from IPython.display import Image, display\n","from tensorflow.keras.preprocessing.image import load_img\n","import PIL\n","from PIL import ImageOps\n","m = tf.keras.metrics.AUC()\n","\n","\n","val_input_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Grises/Validacion/Img\"\n","val_target_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Grises/Validacion/Mask\"\n","\n","#val_input_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Mejoradas/Validacion_Total/Img\"\n","#val_target_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Mejoradas/Validacion_Total/Mask\"\n","\n","#val_input_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Normales/Validacion_Total/Img\"\n","#val_target_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Normales/Validacion_Total/Mask\"\n","\n","#val_input_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Combinadas/Validacion_T/Img\"\n","#val_target_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Combinadas/Validacion_T/Mask\"\n","\n","ret= 0\n","\n","val_input_paths = sorted(\n","    [\n","        os.path.join(val_input_it, fname)\n","        for fname in os.listdir(val_input_it)\n","        if fname.endswith(\".png\") and not fname.startswith(\".\")\n","    ]\n",")\n","\n","val_target_paths = sorted(\n","    [\n","        os.path.join(val_target_it, fname)\n","        for fname in os.listdir(val_target_it)\n","        if fname.endswith(\".png\") and not fname.startswith(\".\")\n","    ]\n",")\n","\n","\n","for l in range(10):\n","    img_1= load_img(val_input_paths[l], target_size=(400, 400, 3))\n","    img_1= (np.array(img_1).reshape(-1,400,400,3))/255.0\n","    val_preds = model.predict(img_1)\n","    mask = np.argmax(val_preds[0], axis=-1)\n","    mask = np.expand_dims(mask, axis=-1)\n","\n","    im = load_img(val_target_paths[l], target_size= (400, 400), color_mode=\"grayscale\")  \n","    y= np.array(im).reshape(400,400,1)\n","    for r in range(y.shape[0]):\n","        for g in range(y.shape[1]):\n","            if y[r, g, 0]!= 0:\n","                y[r, g, 0]= 1\n","\n","    m.update_state(y, mask)\n","    ret= ret + m.result().numpy()\n","\n","ret= ret/10\n","print(ret)\n","    \n","\n","#img = PIL.ImageOps.autocontrast(tf.keras.preprocessing.image.array_to_img(mask))\n","#plt.imshow(img, cmap=\"gray\")\n","#plt.show()\n","#plt.imsave(\"SGD_Norm.png\", img, cmap=\"gray\")\n","#display(img)"],"outputs":[],"metadata":{"id":"G0OivsaYZd4i","outputId":"a02d18f3-c40f-4d87-e68a-b2b3cf2dc239"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","\n","#from IPython.display import Image, display\n","from tensorflow.keras.preprocessing.image import load_img\n","import PIL\n","from PIL import ImageOps\n","\n","val_input_it= \"E:/rortiz324/Proyecto/Bases_de_datos/Imagenes_Grises/Validacion/Img/0.png\"\n","\n","img_1= load_img(val_input_it, target_size=(400, 400, 3))\n","img_1= (np.array(img_1).reshape(-1,400,400,3))/255.0\n","val_preds = model.predict(img_1)\n","mask = np.argmax(val_preds[0], axis=-1)\n","mask = np.expand_dims(mask, axis=-1)\n","\n","img = PIL.ImageOps.autocontrast(tf.keras.preprocessing.image.array_to_img(mask))\n","plt.imshow(img, cmap=\"gray\")\n","plt.show()\n","plt.imsave(\"SGD_Comb.png\", img, cmap=\"gray\")"],"outputs":[],"metadata":{"id":"jV5KuSElZd4j","outputId":"6cccdda0-6721-463b-89d3-a2e1a0cad875"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"gt5jjblsZd4j"}}]}